{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75de9ee",
   "metadata": {},
   "source": [
    "Step 1: Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d0af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d550ca6",
   "metadata": {},
   "source": [
    "Step 2: Defining input size, hidden layer size, output size and batch size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531dfbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in, n_h, n_out, batch_size = 10, 5, 1, 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ff1c6f",
   "metadata": {},
   "source": [
    "Step 3: Create input and target tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeaa4c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, n_in)\n",
    "y = torch.tensor([[1.0], [0.0], [0.0], \n",
    "[1.0], [1.0], [1.0], [0.0], [0.0], [1.0], [1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed763e3",
   "metadata": {},
   "source": [
    "Step 4: Create a Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b43bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(n_in, n_h), nn.ReLU(), nn.Linear(n_h, n_out), nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcaf28",
   "metadata": {},
   "source": [
    "Step 5: Construct the loss function with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "574c59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d79653",
   "metadata": {},
   "source": [
    "Step 6: Implement the gradient descent model with the iterating loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7490a23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  0.2536523640155792\n",
      "epoch:  1 loss:  0.253481924533844\n",
      "epoch:  2 loss:  0.2533118724822998\n",
      "epoch:  3 loss:  0.25314217805862427\n",
      "epoch:  4 loss:  0.25297287106513977\n",
      "epoch:  5 loss:  0.25280389189720154\n",
      "epoch:  6 loss:  0.25263532996177673\n",
      "epoch:  7 loss:  0.25246715545654297\n",
      "epoch:  8 loss:  0.25229936838150024\n",
      "epoch:  9 loss:  0.2521319091320038\n",
      "epoch:  10 loss:  0.25196486711502075\n",
      "epoch:  11 loss:  0.251798152923584\n",
      "epoch:  12 loss:  0.25163182616233826\n",
      "epoch:  13 loss:  0.2514658570289612\n",
      "epoch:  14 loss:  0.25130024552345276\n",
      "epoch:  15 loss:  0.2511350214481354\n",
      "epoch:  16 loss:  0.2509700655937195\n",
      "epoch:  17 loss:  0.2508055567741394\n",
      "epoch:  18 loss:  0.2506413757801056\n",
      "epoch:  19 loss:  0.25047749280929565\n",
      "epoch:  20 loss:  0.25031402707099915\n",
      "epoch:  21 loss:  0.2501506209373474\n",
      "epoch:  22 loss:  0.24995699524879456\n",
      "epoch:  23 loss:  0.2497677356004715\n",
      "epoch:  24 loss:  0.24959218502044678\n",
      "epoch:  25 loss:  0.2494169920682907\n",
      "epoch:  26 loss:  0.24924209713935852\n",
      "epoch:  27 loss:  0.2490675449371338\n",
      "epoch:  28 loss:  0.24889323115348816\n",
      "epoch:  29 loss:  0.24871930480003357\n",
      "epoch:  30 loss:  0.24854567646980286\n",
      "epoch:  31 loss:  0.24837228655815125\n",
      "epoch:  32 loss:  0.24819926917552948\n",
      "epoch:  33 loss:  0.24802646040916443\n",
      "epoch:  34 loss:  0.2478540688753128\n",
      "epoch:  35 loss:  0.24768182635307312\n",
      "epoch:  36 loss:  0.24750995635986328\n",
      "epoch:  37 loss:  0.24733833968639374\n",
      "epoch:  38 loss:  0.24716699123382568\n",
      "epoch:  39 loss:  0.2469959706068039\n",
      "epoch:  40 loss:  0.2468252182006836\n",
      "epoch:  41 loss:  0.2466546595096588\n",
      "epoch:  42 loss:  0.24648448824882507\n",
      "epoch:  43 loss:  0.24631448090076447\n",
      "epoch:  44 loss:  0.24614480137825012\n",
      "epoch:  45 loss:  0.2459753304719925\n",
      "epoch:  46 loss:  0.24580609798431396\n",
      "epoch:  47 loss:  0.2456371784210205\n",
      "epoch:  48 loss:  0.24546849727630615\n",
      "epoch:  49 loss:  0.24530000984668732\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent\n",
    "for epoch in range(50):\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    loss = criterion(y_pred, y)\n",
    "    print('epoch: ', epoch, 'loss: ', loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a80685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
